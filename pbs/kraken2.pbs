#!/usr/bin/env bash

# kraken2.pbs

# Run kraken2

# Vivian Leung
# Created:       03 Jan 2024
# Last updated:  03 Jan 2024
# Last used:     03 Jan 2024

### Job name
### Queue name (qaussian): stdq1, medq1, fatq1 or gpuq1
### Wall time required (between 00:00:01 to 336:00:00).
### Number of CPUs: ppn: up to 40 for stdq1, 48 for gpuq1, 64 for medq1 and fatq1
### Memory: up to 750gb for stdq1, 1000gb for medq1 and gpuq1, 3000gb for fatq1

#PBS -N 20240102-kraken2_build_nt
#PBS -q quickq1
#PBS -l walltime=6:00:00
#PBS -l select=1:ncpus=40:mem=750gb

## Generally fixed settings
#__PBS -M vivian
#__PBS -m ae
#PBS -M leungvw@connect.hku.hk
#PBS -v MODULEPATH

### Declare job non-rerunable
#PBS -r n
#PBS -k oed

#######
set -e
set -o nounset
set -o errtrace
set -o pipefail

export start_time=$(date +'%s.%N') DRY_RUN= KEEP_TMP= NO_TMPDIR=

DRY_RUN='n'
KEEP_TMP='n'
NO_TMPDIR=1
# NO_TMPDIR=0  # don't make tmpdir   # for socket

############ SPECS AND PARAMS ############

# I/O

# constants exports for pbsutils and jobs
export PROJECT_DIR DATA_DIR INPUT_DIR OUT_DIR ROSTER
declare -A INPATHS OUT_DIRS OUTFILES

# key directories
PROJECT_DIR="/home/d24h_prog2/data_share/ice_water"
DATA_DIR="$PROJECT_DIR/data"
# INPUT_DIR="$DATA_DIR"

INPUT_DIR=/home/d24h_prog2/PUBLIC_DB/kraken2

# # Headerless tsv with paired fastqs relpaths (relative to input dir)
# ROSTER="$INPUT_DIR/trimmed_fqs.tsv"

export KRAKEN_DB=/home/d24h_prog2/PUBLIC_DB/kraken2/nt

# assoc array for easier logging
INPATHS=(
    # [roster]="$ROSTER"
    [input_dir]="$INPUT_DIR"
    [kraken_db]="$KRAKEN_DB"
)

# Job output dir
OUT_DIR="${PROJECT_DIR}/jobs/${PBS_JOBNAME}-${PBS_JOBID%%.*}"

# output dirs to make
OUT_DIRS=(
    [main]="${OUT_DIR}"
)

# environment settings
declare CONDA_ENV MODULES

CONDA_ENV="vivian"
MODULES=(
    'vivian/kraken2/2.1.3'
    'vivian/bracken/2.9'
)

# Exports: duration timestamp print_array print_params set_conda_env
#          DEFAULT_CONDA_PREFIX
# run /home/d24h_prog2/vivian/utils/utils.sh --help for helpdoc
source "/home/d24h_prog2/vivian/utils/utils.sh"


# i/o flags and options on run
declare -a JOB_ARGS=(
    kraken2-build --build --db "${KRAKEN_DB}" --threads $OMP_NUM_THREADS
)
    # bracken-build -d "${KRAKEN_DB}" -t $OMP_NUM_THREADS -l 75
declare JOB_COMMAND=

  
############ UTILS AND FUNCTIONS  ############
# put things like path generation here

# fq_basename () { basename "$1" | sed -E 's/(_[12])?\.(fq|fastq)(\.gz)?$//' ; }
fq_basename () { basename "$1" | sed -E 's/(_[12])?(\.[^.]+)*\.(fq|fastq)(\.gz)?$//' ; }
export -f fq_basename

# File naming conventions

# usage: path_kraken ACCESSION_OR_FPATH
# path_kraken () {
#     echo "${OUT_DIR}/$(fq_basename "$1").kraken"
# }
# export -f path_kraken


# examples
OUTFILES+=(
)

############  STANDARD/FIXED SETUP  ############

# Common utilities for PBS scripts

# Export PBS variables for pbsutils
export PBS_JOBNAME PBS_NODEFILE PBS_O_WORKDIR OMP_NUM_THREADS

# remove junk in PATH (manually put in by others in ~/.bashrc)
export PATH="$(clean_path "$PBS_O_PATH" -e '^\/home\/d24h_prog2\/' \
      -i '^\/home\/d24h_prog2\/(\.conda|miniconda3|vivian)\/')"

cd $PBS_O_WORKDIR

# Parse PBS variables

# export PBS variables for pbsutils
export NPROCS NNODES NCORES JID

NPROCS=$(wc -l < $PBS_NODEFILE)
NNODES=$(uniq $PBS_NODEFILE | wc -l)
NCORES=$((NPROCS / NNODES))
JID="${PBS_JOBID%%.*}"

# Parse input rosters and logs
export roster n_samples
if [[ -n "${ROSTER+foo}" ]] ; then
    roster="$PBS_O_WORKDIR/$PBS_JOBNAME.$(basename "$ROSTER").$JID"
    cp "$ROSTER" "$roster"
    n_samples=$(wc -l <"${roster}")
fi

# Save this pbs job script to jobs dir
cp "$0" "$PBS_O_WORKDIR/$PBS_JOBNAME.pbs.$JID"

##  Prep environment ##

# init conda env
set_conda_env "$CONDA_ENV"

# import modules
for mod in "${MODULES[@]}" ; do module load "${mod}" ; done

# this must come after defining all of the below exported
# exports: is_dry_run do_keep_tmp epilogue epilogue_simple trap_error
#          trap_finish_job standard_prologue io_prologue
source "/home/d24h_prog2/vivian/utils/pbsutils.sh"

trap trap_error ERR
trap epilogue_simple EXIT

# print info about PBS and environment
standard_prologue

io_prologue 'INPATHS' 'OUT_DIRS' 'OUTFILES'

############  END OF STANDARD/FIXED SETUP  ############

# Report params and programs
cat <<-PROLOGUE_PROGRAMS_PARAMS

	============== Programs in Use ==============
	> kraken2:  $(kraken2 --version 2>&1)
	$(which kraken2)

	> bracken:  $(bracken -v 2>&1)
	$(which bracken)

	============ Common Command Params ============
	> kraken2/bracken
	$( (( ${#JOB_ARGS[@]} > 0 )) &&  print_params "$JOB_ARGS[@]}" || echo "${JOB_COMMAND}")
PROLOGUE_PROGRAMS_PARAMS


####################  EXECUTE  ####################

printf "============== EXECUTING..... ==============\n"

# make output dirs
mkdir -p "${OUT_DIR}"
mkdir -pv "${OUT_DIRS[@]}"

# make tmpdir
if [[ ${NO_TMPDIR:-0} == 0  ]] ; then
  TMPDIR="$(mktemp -d)"
else
  mktempdir
# shorten path
  export TMPDIR="$(realpath --relative-to="${INPUT_DIR}" $TMPDIR)"
fi

# important: go to directory
cd "${INPUT_DIR}"

printf '%s Running kraken2/bracken\n' "$(timestamp)"

[[ -z "${n_samples:-}" ]] || printf '%s %d samples\n' "$(timestamp)" ${n_samples}

(( ${#JOB_ARGS[@]} > 0 )) && eval "${JOB_ARGS[@]}" || eval "${JOB_COMMAND}"


